{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevendo a nota final dos alunos da Escola Todos Unidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importações de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from yellowbrick.model_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from graphviz import render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas = pd.read_csv('student-mat.csv')\n",
    "df_notas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificação de dados faltantes\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum() # conta a quantidade de missing\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df) # calcula a porcentagem\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) # cria uma tabela\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Valores faltantes', 1 : '% do total'}) # renomeia as colunas\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% do total', ascending=False).round(1) # ordena os valores\n",
    "        print (\"Você selecionou um dataframe que tem \" + str(df.shape[1]) + \" colunas.\\n\"      \n",
    "            \"E há \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" colunas com valores faltantes\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = missing_values_table(df_notas)\n",
    "missing_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação da planilha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRATANDO DADOS CATEGÓRICOS: Transformar variáveis categóricas em numéricas\n",
    "Para análise comparativa das variáveis, precisamos que todas fiquem numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorias com strings\n",
    "categoricas = ['school',\\\n",
    "               'sex',\\\n",
    "              'address',\\\n",
    "              'famsize',\\\n",
    "               'Pstatus',\\\n",
    "               'Mjob',\\\n",
    "               'Fjob',\\\n",
    "               'reason',\\\n",
    "               'guardian',\\\n",
    "               'schoolsup',\\\n",
    "               'famsup',\\\n",
    "               'paid',\\\n",
    "               'activities',\\\n",
    "               'nursery',\\\n",
    "               'higher',\\\n",
    "               'internet',\\\n",
    "               'romantic',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher o melhor método (um ficará comentado)\n",
    "le = LabelEncoder()\n",
    "# apply le on categorical feature columns\n",
    "df_notas[categoricas] = df_notas[categoricas].apply(lambda col: le.fit_transform(col))\n",
    "df_notas[categoricas].head( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oe = OrdinalEncoder()\n",
    "#categorical = df_notas[categoricas]\n",
    "#oe.fit(categorical)\n",
    "#numerical = oe.transform(categorical)\n",
    "\n",
    "#for n, feat in enumerate(categoricas):\n",
    "#    df_notas[feat] = numerical[:, n]\n",
    "#df_notas.head( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados\n",
    "A normalização dos dados coloca-os na mesma ordem de grandeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este processo PADRONIZA as variáveis\n",
    "scala = StandardScaler().fit(df_notas)\n",
    "df_notasN = escala.transform(df_notas)\n",
    "df_notas = pd.DataFrame(StandardScaler().fit_transform(df_notasN), columns=df_notas.columns, index=df_notas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este processo NORMALIZA as variáveis - ESCOLHER APENAS UM PROCESSO\n",
    "#escala = Normalizer().fit(df_notas)\n",
    "#df_notasN = escala.transform(df_notas)\n",
    "#df_notas = pd.DataFrame(Normalizer().fit_transform(df_notasN), columns=df_notas.columns, index=df_notas.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo gráficos de demonstração de importância das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_notas.drop('G3', axis=1)\n",
    "y = df_notas['G3']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados preparados para escolha do tipo de algoritmo\n",
    "O algoritmo escolhido após vários testes foi o DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gera um gráfico com a melhor quantidade de variáveis a ser considerada e quais são elas\n",
    "#cv = StratifiedKFold(5) - LINHA COMENTADA PQ O CROSSVALIDATION ESTAVA DANDO ERRO DE VARIÁVEL TIPO CONTINUOUS\n",
    "visualizer = RFECV(RandomForestRegressor(), cv=5, scoring='r2')\n",
    "visualizer.fit(X, y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, X.columns != 'IN_TREINEIRO'].columns[visualizer.support_] #pegar as colunas que ele retornou como importante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depois de aplicar o Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria planilha nova SEM as features que o Yellowbrick considerou sem importância\n",
    "df_notas3 = df_notas.drop(['school', 'sex', 'address', 'famsize', 'Pstatus', 'guardian', 'schoolsup', 'famsup', 'paid', \n",
    "                           'nursery', 'higher', 'internet', 'romantic', 'Dalc', 'G3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_notas3\n",
    "y = df_notas['G3']\n",
    "regressor2= DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "#Variável teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#fit tregressor with X and y data\n",
    "regressor2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas do Modelo só com as colunas indicadas no Yellowbrick como importantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliação da qualidade do modelo\n",
    "print('Score:', score = regressor2.score(X_test, y_test))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred)) #próx de 0, melhor\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) #medida de dispersão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando o regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n = X.columns\n",
    "regr_2 = DecisionTreeRegressor()\n",
    "regr_2.fit(X, y)\n",
    "DTR_teste = regr_2.feature_importances_\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(DTR_teste))], DTR_teste)\n",
    "plt.xticks([x for x in range(len(DTR_teste))], features_n, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planilha completa - DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_notas.drop('G3', axis=1)\n",
    "y = df_notas['G3']\n",
    "regressor2= DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "#Variável teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#fit tregressor with X and y data\n",
    "regressor2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas do modelo Planilha completa - DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score:', score = regressor2.score(X_test, y_test))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred)) #próx de 0, melhor\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) #medida de dispersão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando o regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n = X.columns\n",
    "regr_2 = DecisionTreeRegressor()\n",
    "regr_2.fit(X, y)\n",
    "DTR_teste = regr_2.feature_importances_\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(DTR_teste))], DTR_teste)\n",
    "plt.xticks([x for x in range(len(DTR_teste))], features_n, rotation='vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
